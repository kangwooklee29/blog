### 1. 손실함수

\- linear classification에서 좋은 결과를 내기 위해서는 보다 나은 가중치 행렬을 얻어야 한다. 이를 위해 우선 가중치 행렬의 좋고 나쁨을 정량화할 수 있어야 하는데, 보통 손실함수(loss function)의 값을 이용해 가중치 행렬의 좋고 나쁨을 수치로 정량화한다. 그리고 손실함수를 이용해서 최선의 가중치 행렬을 구하는 과정을 최적화(optimization)이라 한다.

\- 손실함수는 주어진 데이터에 관한 **예측함수 함수값 열벡터**와 **실제 그 데이터의 classification에 관한 열벡터**를 통해 함수값을 계산하는 함수이다. 구체적으로, 가중치 행렬 \\(W\\)와 입력 데이터 열벡터 \\(x\\), 그 입력 데이터가 실제 갖는 classification에 관한 열벡터 \\(y\\)가 주어지며 또 \\(x, W\\)를 인자로 하는 예측 함수 \\(f\\)로 얻은 함수값 열벡터 \\(f(x, W)\\)가 있다 할 때, 손실함수 \\(L\\)은 \\(f(x, W)\\)와 \\(y\\)를 인자로 하는 함수이다.


### 2. multi-class SVM

\- 손실함수에 관한 구체적인 사례로 multi-class SVM이라는 손실함수가 있으며, 입력 데이터 열벡터 \\(x\\)와 그에 대한 classification 열벡터 \\(y\\)에 대해 그때의 multi-class SVM 손실함수 \\(L\\)은 다음과 같이 정의된다.

$$
L(f(x, W), y) = \sum_{i \ne j} max(0,  s_j - s_k + 1) \\
$$


- \\(s_j\\): 예측함수의 함수값 열벡터 \\(f(x_i, W)\\)의 \\(j\\)행의 성분을 뜻한다. 

- \\(s_k\\): \\(x_i\\)에 대응되는 열벡터 \\(y_i\\)가 \\(k\\)행의 성분만 0이 아니고 나머지는 모두 0이라