### 1. 행렬의 곱셈


$$ 
\begin{bmatrix} 
* & \cdots &  * \\ 
\vdots & a_{i, k} & \vdots \\
* & \cdots &  * 
\end{bmatrix}  

\begin{bmatrix} 
* & \cdots &  * \\ 
\vdots & b_{k, j} & \vdots \\
* & \cdots &  * 
\end{bmatrix}  

=

\begin{bmatrix} 
* & \cdots &  * \\ 
\vdots & c_{i, j} & \vdots \\
* & \cdots &  * 
\end{bmatrix}  


$$ 



\- 크기가 \\(n \times r\\)인 행렬 \\(A\\)의 각 성분을 \\(a_{i, k}\\)라 하고 크기가 \\(r \times m\\)인 행렬 \\(B\\)의 각 성분을 \\(c_{k, j}\\)라 할 때, 이 두 행렬의 곱 \\(A \cdot B\\)는 각 성분 \\(c_{i, j} = \sum_{k=1}^n a_{i, k} \cdot b_{k, j}\\)로 정의되는 크기가 \\(n \times m\\)인 행렬로 정의된다.

\- 행렬의 곱셈을 계산할 때 결과 행렬의 각 성분을 계산할 때에는 행렬 \\(A\\)나 행렬 \\(B\\)의 성분을 참조할지언정 곱셈 연산의 다른 결과값을 사용해 현재 곱셈 연산을 수행하는 것은 아님을 알 수 있다. 이는 각 성분을 계산하는 일을 서로 다른 프로세서를 통해 독립적으로 수행할 수 있음을 뜻하며, 병렬 프로세싱을 통해 빠르게 계산을 수행할 수도 있음을 뜻한다.


### 2. 분할행렬

![008i3skNgy1gpyj5xxlszj30qt07ugox](https://user-images.githubusercontent.com/69514453/145963026-5e018d56-ce17-4185-b5c1-2ba5892eb9ac.jpg)

$$
A' = 
\begin{bmatrix} 
A_{11} & A_{12} & A_{13} \\
A_{21} & A_{22} & A_{23}
\end{bmatrix}  

$$

![008i3skNgy1gpyj87t3xqj30y2075wir](https://user-images.githubusercontent.com/69514453/145964601-e5b066ea-ad9f-482a-a044-73eaf869d658.jpg)



\- 행렬의 각 성분이 행렬인 행렬을 생각할 수 있고, 그 행렬의 각 성분 행렬을 순서대로 나열한 후 서로 이어붙인 행렬을 생각할 수 있다. 이 두 행렬은 덧셈/뺄셈은 물론이고 **곱셈 연산에 대해서도 동일한 결과**를 내므로 이 두 행렬을 서로 같다고 정의할 수도 있다.

\- 이러한 관점에서, 행렬을 열벡터 또는 행벡터의 모음으로 볼 수도 있다.


### 3. 행렬변환

\- 정의역과 공역이 모두 벡터인 함수를 변환(transformation)이라 한다. 변환의 정의역과 공역에 들어가는 벡터의 차수는 서로 다를 수 있다. 만약 두 차수가 서로 동일하다면 그러한 변환을 연산자(operator)라 한다.

\- 어떤 변환 \\(T : \mathbb{R}^n \longrightarrow \mathbb{R}^m\\)이 있고 \\(\mathbf{u}, \ \mathbf{v} \in \mathbb{R}\\), \\(c \in \mathbb{R}^m\\) 일 때, \\(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\\) 이고 \\(T(c\mathbf{u})=c T(\mathbf{u})\\) 라면 이러한 변환 \\(T\\)를 선형변환(linear transformation)이라 한다.

- \\(m \times n\\) 행렬에 n-열벡터를 곱하는 연산은 변환 결과로 m-열벡터를 구하는 선형변환의 하나다.

- **모든 선형변환**은 **행렬을 곱하는 연산**으로 표현이 가능하다.



### 4. 행렬변환 코딩

\- 개념적으로 어떤 정의역 벡터에 대해 어떤 결과 벡터를 내는 변환 행렬을 찾고자 하지만 그 변환 행렬을 아직 알지는 못한다면, 다음과 같은 과정을 통해 그 변환 행렬을 찾을 수 있다.

(1) 정의역이 벡터가 맞는지, 그에 대해 얻고자 하는 결과 또한 벡터가 맞는지를 생각한다.

(2) 치역이 만드는 공간이 선형적인지 생각한다.

(3) 각 단위 열벡터 \\(\mathbf{e}_i\\)가 그 변환을 거칠 때 나오는 결과값 열벡터( \\( T(\mathbf{e}_i) \\) )들을 묶어 하나로 잇는다. (즉, 구하고자 하는 변환 \\(T : \mathbb{R}^n \longrightarrow \mathbb{R}^m\\) 의 변환 행렬 \\(A = \begin{bmatrix} T(\mathbf{e}_1) & \cdots & T(\mathbf{e}_n) \end{bmatrix} \\) 이다. )



### 5. SVD

\- 모든 \\(m \times n\\) 행렬은 \\(m \times m\\) 회전행렬(흔히 \\(U\\)라 한다) \\(\times\\) \\(m \times n\\) 대각행렬(흔히 \\(D\\)라 한다) \\(\times\\) \\(n \times n\\) 회전행렬(흔히 \\(V\\)라 한다)의 전치행렬의 곱으로 인수분해 할 수 있으며, 이러한 인수분해를 특이값 분해(singular value decomposition)이라 한다.

\- 행렬의 곱셉은 좌표계 변환으로 볼 수 있다고 했으므로, 특이값 분해를 통해 \\(m \times n\\) 행렬을 다음과 같은 과정을 거쳐 얻어낸 행렬로 볼 수 있다.

(1) n차원 직교좌표계 벡터(=항등행렬)를 회전행렬 V로 회전시킨다.

(2) 회전된 결과의 각 축을 대각행렬 D로 증폭시킨다. (m이 n보다 크다면, 이때 m-n개의 새로운 축이 추가된다.)

(3) 앞선 결과를 회전행렬 U로 회전시킨다.


\- 특이값 분해는 n개의 m-벡터가 주어졌을 때 이들이 어떤 방향으로 강한 응집성을 보이는지 분석하고 이들 벡터들과 유사한 방향으로 응집성을 가지면서 그 응집성이 더 강한 근사 벡터들을 구하는 데 응용할 수 있다. 어떤 \\(m \times n\\) 행렬이 있을 때, 이의 특이값 분해 U, D, V 행렬을 구한 후 각 행렬의 왼쪽에서부터 p개(단, n > p)의 열벡터를 골라(D 행렬의 대각선 성분이 **크기순으로 정렬돼서 구해지기 때문**에 왼쪽에서부터 순서대로 고르는 것이다) 이들로 새로운 U, D, V 행렬을 구해 곱하면 처음 행렬의 근사 행렬이 구해진다. 












