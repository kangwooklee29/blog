### 1. 개요

\- 어떤 확률분포가 있어 주어진 입력에 대한 확률값을 계산할 수 있을 때, 그 확률값에 기반해 최적의 결정을 내리는 이론을 결정이론(decision theory)이라 한다. 이미 계산된 확률분포를 통해 주어진 입력에 대한 확률값을 계산하는 단게(추론단계)와 계산된 확률값에 기반해 최적의 결정을 내리는 단계(결정단계)로 나뉜다.

\- 분류문제를 결정이론으로 접근해 보자. 예를 들어 주어진 입력 \\(\mathbf{x}\\)이 있고 이를 \\(n\\)개의 사건 \\(C_i\\)(\\(i=1, \cdots, n\\)) 중 어느 하나로 분류하는 문제가 있다 하면, 이 분류문제는 모든 \\(i\\)에 대하여 \\(p(C_i \mid \mathbf{x})\\)를 계산한 후(추론단계) 주어진 입력을 그 중 계산된 확률값이 가장 큰 \\(C_i\\)로 분류하여 풀 수 있다.

\- 입력이 실수로 주어진다 할 때, '그 입력이 어떤 값을 기준으로 하는 영역일 때 이를 각 사건으로 분류하는 게 최적인지'를 생각할 수 있다. 예를 들어 모든 \\(i\\)(\\(i=1, \cdots, n\\))에 대해, 가우스 분포 형태를 갖는 확률밀도함수 \\(p_{C_i}(x)\\)가 \\(x\\)가 \\(\mathcal{R}_i\\)라는 영역에서 극댓값을 갖고 \\(x\\)가 \\(\mathcal{R}_i\\)일 때 그 \\(x\\)를 \\(C_i\\)에 분류하도록 한다면, 이러한 모델이 입력 \\(x\\)를 올바르게 분류할 확률은 \\(\sum_i=1^n \int_{\mathcal{R}_ i} p_{C_i}(x) dx\\)가 된다.


### 2. 기대손실 최소화

\- 결정이론에서 모든 결정이 동등한 리스크를 갖는 것은 아니다. 예를 들어 암환자를 정상이라고 분류하는 것과 정상인을 암환자로 분류하는 것의 리스크는 전자가 훨씬 더 큰 리스크를 가질 수밖에 없다. 

\- 분류문제에서 이처럼 각 분류가 서로 다른 리스크를 갖는다는 점을 고려하여 손실함수에 대하여 **각 분류마다 서로 다른 가중치를 두어** 입력 데이터를 **어느 하나로 분류했을 때의 기대손실**을 계산하고 그 기대손실을 최소화하는 손실함수를 구할 수 있다.

- 구체적으로, 원래는 \\(C_k\\)에 속하는 입력 데이터를 \\(C_j\\)로 분류했을 때 발생하는 손실 가중치가 \\(L_{k, j}\\)로 주어지는 손실행렬 \\(L\\)이 있을 때, 이 \\(L\\)에 대한 기대손실 \\(\mathbb{E}(L) = \sum_k \sum_j \int_{R_j} L_{k, j} p_{C_k}( \mathbf{x}) d \mathbf{x} \\)로 쓸 수 있다. 

- 만약 \\(\mathbf{x}\\)라는 입력이 주어질 때 이를 최적의 \\(C_i\\)로 분류하는 함수를 \\(\hat{C}(\mathbf{x})\\)라 하고 손실행렬 \\(L\\)이 주어진다면, 기대손실 식은 \\(\int \sum_k=1^K L_{k, \hat{C}(\mathbf{x})} p_{C_k}(\mathbf{x})d \mathbf{x} = \int \sum_k=1^K L_{k, \hat{C}(\mathbf{x})} p(C_k \mid \mathbf{x}) p(\mathbf{x})d \mathbf{x} \\) 로 쓸 수 있다. 이때 이 식은 입력으로 \\(\hat{C}(\mathbf{x}\\)를 갖는 범함수(functional)이며, 이 분류문제는 기대손실 식을 최소로 하는 \\(\hat{C}(\mathbf{x}\\)를 구하는 문제가 된다.

  이때 \\(\hat{C}(\mathbf{x} = \mathrm{argmin}_j \sum_k=1^K L_{k, j} p(C_k \mid \mathbf{x})\\) 로 쓸 수 있다.