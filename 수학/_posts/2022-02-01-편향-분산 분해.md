\- 제곱합 손실함수가 주어질 때 입력 데이터 \\(\mathbf{x}\\)에 대한 최적 예측값 \\(\mathbb{E}(t \mid \mathbf{x}) = \int t p(t \mid \mathbf{x}) dt\\)을 \\(h(\mathbf{x})\\)라 하면, 손실함수의 기댓값 \\(\mathbb{E}(L) = \int \\{y(\mathbf{x}) - h(\mathbf{x})\\}^2 p(\mathbf{x})d\mathbf{x} + \iint \\{y(h(\mathbf{x})-t\\}^2 p(\mathbf{x}, t)d\mathbf{x}dt\\) 이다.

\- 데이터셋의 크기에는 한계가 있기 때문에 \\(h(\mathbf{x})\\)를 정확히 알 수는 없다. 다만 손실함수의 기댓값을 최소화할 수는 있다. 

\- 어떤 데이터셋 \\(\mathcal{D}\\)로 훈련시킨 모델이 \\(y(\mathbf{x}, \mathcal{D})\\)이라 하면 이때의 손실함수 \\(L(\mathcal{D}) = \\{y(\mathbf{x}, \mathcal{D}) - h(\mathbf{x})\\}^2\\)로 쓸 수 있으며, 이 손실함수의 기댓값 \\(\mathbb{E}(L(\mathcal{D})) = \int \\{y(\mathbf{x}, \mathcal{D}) - h(\mathbf{x})\\}^2 p(\mathbf{x})d\mathbf{x} + n\\)으로 쓸 수 있다.

- 만약 \\(L\\)개의 데이터셋 \\(\mathcal{D}_1, \cdots, \mathcal{D}_L\\)에 대하여 각각 손실함수의 기댓값을 구한 후 이들의 평균을 낸다 하면, 그 손실함수 기댓값 평균은 \\(\displaystyle \int \mathbb{E} _ {\mathcal{D} }(\\{y(\mathbf{x}, \mathcal{D}) - h(\mathbf{x})\\}^2)p(\mathbf{x})d\mathbf{x} + n \\) 으로 쓸 수 있다. 

- 위 식에서 \\( \mathbb{E}_ {\mathcal{D} }(\\{y(\mathbf{x}, \mathcal{D}) - h(\mathbf{x})\\}^2) = \\{\mathbb{E}_ {\mathcal{D} }(\\{y(\mathbf{x}, \mathcal{D}) - h(\mathbf{x})\\}^2 + \mathbb{E}_ {\mathcal{D} }(\\{y(\mathbf{x}, \mathcal{D}) - \mathbb{E}_ {\mathcal{D} }(y(\mathbf{x}, \mathcal{D}))\\}^2)\\) 을 얻는다. 이 전개의 첫 번째 항이 데이터셋에 대한 편향을 의미하고 두 번째 항이 데이터셋에 대한 분산을 의미한다. 편향값이 작으면 과적합이 일어나고, 크면 과소적합이 일어난다. 분산이 작으면 과소적합이 일어나고, 크면 과적합이 일어난다.