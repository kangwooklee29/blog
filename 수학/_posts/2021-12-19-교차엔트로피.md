### 1. 정보

\- 정보이론에서 정보(information)는 **불확실한 정도(uncertainty)**를 측정하는 **양**의 표현(quantitative representation)으로 정의된다. 즉, 일어날 가능성이 불확실한 사건일수록 그 사건이 실제로 일어났음을 전하는 정보는 더 정보량이 많은 것(informative)으로 볼 수 있다. 이러한 정의를 따라, 사건 \\(A\\)의 정보량 \\(i(A)\\) 는 \\(-log P(A)\\), 즉 사건 \\(A\\)가 실제 일어날 확률의 역수에 로그를 취한 값으로 정의된다.

- 사건 \\(A\\)가 실제 일어날 확률이 높다면 사건 \\(A\\)의 정보의 크기는 작고, 반대로 사건 \\(A\\)가 실제 일어날 확률이 낮다면 사건 \\(A\\)의 정보의 크기는 크다.

- 사건 \\(A\\)와 사건 \\(B\\)가 서로 독립이라면, 두 사건이 동시에 일어나는 정보의 크기 \\(i(A \cap B) = i(A) + i(B)\\) 이다.