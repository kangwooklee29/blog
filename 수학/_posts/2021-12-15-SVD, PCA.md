---

title: SVD, PCA

---




### 1. 대칭행렬의 직교대각화

#### 1) 선형독립(linearly independent)

\- 어떤 \\(n \times n\\) 행렬 \\(A\\)가 있고 이를 구성하는 n차원 열벡터를 각각 \\(\mathbf{a}_1, \cdots, \mathbf{a}_n\\)라 할 때, 만약 \\( A \mathbf{x} = \mathbf{0}\\)**을 만족하는 열벡터 \\(\mathbf{x}\\)가 \\(\mathbf{0}\\)로 유일**하다면 이때 **열벡터 \\(\mathbf{a}_1, \cdots, \mathbf{a}_n\\)들끼리는 모두 선형독립**이라고 한다. 

\- 선형독립을 linear system의 관점에서 보면, 열벡터 \\(\mathbf{a}_1, \cdots, \mathbf{a}_n\\)이 모두 선형독립이라는 것은 **linear system \\( A \mathbf{x} = \mathbf{0}\\)의 해가 유일**함을 뜻한다. 이는 **행렬 \\(A\\)의 역행렬 \\(A^{-1}\\)이 존재한다는 것과 동치**이다.

\- 서로 선형독립 관계라면, 그 중 어느 한 벡터도 선형독립 관계인 다른 벡터들의 선형 결합으로 표현될 수 없다.

\- 직교와 선형독립: 서로 직교하는 관계인 벡터끼리는 서로 선형독립이기도 하다. (단, 선형독립 관계인 벡터는 반드시 서로 직교하는 것은 아니다.)


#### 2) 고유값 분해

\- \\(n \times n\\) 행렬이 고유값을 \\(n\\)개 이상 갖는다면 그 행렬을 그때의 고유벡터들로 만든 행렬과 각 성분이 고유값인 대각행렬의 곱셈 꼴로 표현할 수 있으며, 이를 고유값 분해(eigenvalue decomposition) 또는 대각화(diagonalization)라 한다.

\- 구체적으로, 어떤 \\(n \times n\\) 행렬 \\(A\\)의 고유값이 \\(\lambda_1\\)부터 \\(\lambda_n\\)까지 총 n개 있고 그때의 고유벡터가 \\(\mathbf{v}_1, \cdots, \mathbf{v}_n\\)이라 하면, 이 고유벡터들로 만든 행렬 \\(P = \begin{bmatrix} \mathbf{v}_1 & \cdots & \mathbf{v}_n \end{bmatrix}\\)에 대해 다음이 성립한다.

$$

AP = \begin{bmatrix} \lambda_1 \mathbf{v}_1 & \cdots & \lambda_n \mathbf{v}_n \end{bmatrix} = \begin{bmatrix} \mathbf{v}_1 & \cdots & \mathbf{v}_n \end{bmatrix} 

\begin{bmatrix} 
\lambda_1 & \cdots & 0 \\ 
\vdots & \ddots & \vdots \\ 
0 & \cdots & \lambda_n \\ 
\end{bmatrix}

$$

여기서 \\(\Lambda\\)를 다음과 같이 정의할 수 있다.

$$

\Lambda = 
\begin{bmatrix} 
\lambda_1 & \cdots & 0 \\ 
\vdots & \ddots & \vdots \\ 
0 & \cdots & \lambda_n \\ 
\end{bmatrix}

$$

이때 만약 \\(P^{-1}\\)이 존재한다면(=\\(P\\)가 선형독립이면) \\(A = P \Lambda P^{-1}\\)라는 식을 쓸 수 있다.

#### 3) 직교대각화

\- 어떤 행렬이 역행렬이 존재하는 **대칭행렬**이라면 이 행렬은 고유값 분해가 가능하며(\\(\because\\)역행렬이 존재하기 때문) 그 고유값 분해의 고유벡터 행렬은 **직교행렬**임이 알려져 있다. _(즉, 대칭행렬은 고유벡터끼리 서로 직교하며 또 서로 선형독립이기도 하다.)_ 이때 이러한 고유값 분해를 직교대각화라 한다.

\- 행렬 \\(A\\)가 \\(P \Lambda P^{-1}\\) 꼴로 직교대각화가 가능하다 할 때, \\(P^{-1} = P^T\\)이므로(\\(\because P\\)가 직교행렬이기 때문) \\(A = P \Lambda P^T\\)로 쓸 수도 있다. 

$$ 

A = P \Lambda P^{-1} = \begin{bmatrix} \mathbf{v}_1 & \cdots & \mathbf{v}_ n \end{bmatrix} 

\begin{bmatrix} 
\lambda _1 & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & \lambda _n 
\end{bmatrix} 

\begin{bmatrix} \mathbf{v}_1 & \cdots & \mathbf{v}_ n \end{bmatrix}^T

$$

\- 직교대각화는 n개의 m-벡터가 주어졌을 때 **이들이 어떤 방향으로 강한 응집성을 보이는지 분석**하고 이들 벡터들과 유사한 방향으로 응집성을 가지면서 그 응집성이 더 강한 **근사 벡터들**을 구하는 데 응용할 수 있다. 다음과 같은 방법으로 할 수 있다.

(1) 주어진 벡터들로 \\(m \times n\\) 행렬을 만든 후, 이 행렬을 대각선 왼쪽 아래와 오른쪽 위 부분으로 나눈 후 각각에 대하여 정사각 대칭행렬을 만든 후 직교대각화를 한다. (각각의 고유벡터 행렬을 \\(P_1, P_2, \Lambda_1, \Lambda_2\\)라 하자.)

(2) \\(P_1, P_2, \Lambda_1, \Lambda_2\\)의 각 행렬의 왼쪽에서부터 p개(단, n > p)의 열벡터를 골라(단, \\(\Lambda_1, \Lambda_2\\) 행렬의 대각선 성분이 **크기순으로 정렬**돼있는 것으로 전제한다) 이들로 새로운 \\(P, \Lambda\\) 행렬을 구해 곱한 후 결과 행렬을 다시 대각선을 기준으로 나눈 후 이어붙이면 처음 행렬의 근사 행렬이 구해진다.





### 2. 특이값 분해


\- 모든 \\(m \times n\\) 행렬은 [\\(m \times m\\) 회전행렬(흔히 \\(U\\)라 한다)] \\(\times\\) [\\(m \times n\\) 대각행렬(흔히 \\(D\\)라 한다)] \\(\times\\) [\\(n \times n\\) 회전행렬(흔히 \\(V\\)라 한다)의 전치행렬] 꼴로 인수분해 할 수 있으며, 이러한 인수분해를 특이값 분해(singular value decomposition)이라 한다. 각 행렬은 직교대각화를 이용하여 구한다. (역행렬이 존재하는 어떤 행렬과 그 전치행렬의 곱은 대칭행렬이 된다는 성질을 이용한다. 참고로 이는 전치행렬의 자명한 성질인데 전치행렬은 \\((AB)^T = B^T A^T\\)가 성립하기 때문이다.)

\- 행렬의 곱셉은 좌표계 변환으로 볼 수 있다고 했으므로, 특이값 분해를 통해 \\(m \times n\\) 행렬을 다음과 같은 과정을 거쳐 얻어낸 행렬로 볼 수 있다.

(1) n차원 직교좌표계 벡터(=항등행렬)를 회전행렬 V로 회전시킨다.

(2) 회전된 결과의 각 축을 대각행렬 D로 증폭시킨다. (m이 n보다 크다면, 이때 m-n개의 새로운 축이 추가된다.)

(3) 앞선 결과를 회전행렬 U로 회전시킨다.

\- 특이값 분해를 하면 직교대각화보다 훨씬 더 간단한 방법으로 응집성을 분석할 수 있다. n개의 m-벡터로 \\(m \times n\\) 행렬을 만든 후, 이의 특이값 분해 U, D, V 행렬을 구해 각 행렬의 왼쪽에서부터 p개(단, n > p)의 열벡터를 골라(단, D 행렬의 대각선 성분이 **크기순으로 정렬**돼있는 것으로 전제한다) 이들로 새로운 U, D, V 행렬을 구해 곱하면 처음 행렬의 근사 행렬이 구해진다. 



### 3. PCA

\- 주성분 분석(principal component analysis)은, n개의 m차원 좌표 \\(\mathbf{x}_i\\)가 주어졌을 때 이 좌표들이 주로 분포하고 있는 방향벡터를 구하고 각 방향으로 얼만큼 분포하고 있는지를 그 n개의 좌표들로 만든 공분산 행렬을 이용해 분석하는 방법이다. 다음과 같은 방법으로 분석한다.

(1) \\(\mathbf{x}_i\\)의 중심 벡터를 \\(\mathbf{m}\\)이라 할 때, n개의 m차원 좌표 \\(\mathbf{x}_i\\)에 대하여 다음과 같이 정의되는 공분산 행렬 \\(C\\)를 구한다.

$$ C = {1 \over {n} } \sum_{i=1}^n { (\mathbf{x}_i - \mathbf{m}) (\mathbf{x}_i - \mathbf{m})^T } $$


(2) 공분산 행렬 C는 [\\(n \times n\\) 회전행렬(흔히 \\(W\\)라 한다) ]\\(\times\\) [\\(n \times n\\) 대각행렬(흔히 \\(D\\)라 한다)] \\(\times\\) [\\(W^T\\) ] 꼴로 인수분해 할 수 있다. 이때 \\(W\\)와 \\(D\\)는 다음 의미를 갖는다.

- \\(W\\): 데이터들이 주로 분포하고 있는 방향벡터에 관한 정보를 담고 있는 회전행렬

- \\(D\\): 데이터들이 \\(W\\)의 각 벡터들의 방향으로 얼마나 응집되어 있는지를 담고 있는 대각행렬. 크기가 왼쪽 위 성분부터 오른쪽 아래 성분 순으로 정렬돼 있는 것으로 전제한다.



