---
title: CS231n - 손실함수
---


### 1. 손실함수

\- linear classification에서 좋은 결과를 내기 위해서는 보다 나은 가중치 행렬을 얻어야 한다. 이를 위해 우선 가중치 행렬의 좋고 나쁨을 정량화할 수 있어야 하는데, 보통 손실함수(loss function)의 값을 이용해 가중치 행렬의 좋고 나쁨을 수치로 정량화한다. 그리고 손실함수를 이용해서 최선의 가중치 행렬을 구하는 과정을 최적화(optimization)이라 한다.

\- 손실함수는 주어진 데이터에 관한 **예측함수 함수값 열벡터**와 **실제 그 데이터의 classification에 관한 열벡터**를 통해 함수값을 계산하는 함수이다. 구체적으로, 가중치 행렬 \\(W\\)와 입력 데이터 열벡터 \\(x\\), 그 입력 데이터가 실제 갖는 classification에 관한 열벡터 \\(y\\)가 주어지며 또 \\(x, W\\)를 인자로 하는 예측 함수 \\(f\\)로 얻은 함수값 열벡터 \\(f(x, W)\\)가 있다 할 때, 손실함수 \\(L\\)은 \\(f(x, W)\\)와 \\(y\\)를 인자로 하는 함수이다.


### 2. multi-class SVM

#### 1) 손실함수

\- 손실함수에 관한 구체적인 사례로 multi-class SVM이라는 손실함수가 있으며, 입력 데이터 열벡터 \\(x\\)와 그에 대한 classification 열벡터 \\(y\\)에 대해 그때의 multi-class SVM 손실함수 \\(L\\)은 다음과 같이 정의된다.

$$
L(f(x, W), y) = \sum_{i \ne y} max(0,  s_i - s_y + 1) \\
$$


- \\(s_i\\): 예측함수의 함수값 열벡터 \\(f(x, W)\\)의 \\(i\\)행의 성분을 뜻한다. 흔히 \\(i\\)행 레이블에 해당하는 '점수(score)'라고 부르기도 한다.

- \\(s_y\\): \\(x\\)에 대응되는 열벡터 \\(y\\)는 특정 행의 성분만 0이 아니고 나머지는 모두 0인데, \\(s_y\\)는 \\(f(x, W)\\)의 행 중 \\(y\\)의 0이 아닌 행과 같은 행의 성분을 뜻한다.

- \\(max(0, s_i - s_y + 1)\\): \\(s_i\\)가 \\(s_y\\)보다 크거나, 작더라도 그 차이가 1보다 작다면 '그 차이 + 1'이라는 값을 손실함수 값을 계산할 때 합산할 것임을 뜻한다. \\(s_i\\)가 \\(s_y\\)보다 작더라도 그 차이가 1보다 작게 계산된다는 것은 그만큼 **둘 사이 차이가 아주 작다**는 것인데, 이를 통해 그 예측함수가 그만큼 좋은 함수가 아닐 수 있다고 추측할 수 있다.

- \\(\sum_{i \ne y}\\): \\(f(x, W)\\)의 \\(s_y\\)가 있는 행을 제외한 **모든 행**에 대하여 수식을 계산해서 그 값을 합하도록 함을 뜻한다.


\- 보통 초기에는 \\(W\\)의 각 성분이 0에 매우 가깝고 각 성분 사이 차이가 그리 크지 않으므로, \\(s_i - s_y\\)의 차이 또한 그리 크지 않아 손실함수 값이 작게 나오기 마련이다. 만약 이 손실함수에서 \\(s_i - s_y\\) 뒤에 1을 더하지 않았다면 아주 초기에 손실함수값이 0이 나와 더 나은 손실함수를 찾지 않게 했을 것이다. 그러나 이 손실함수는 그런 경우에 대비해 1을 더해줌으로써 \\(W\\)의 모든 성분 사이 차이가 그리 크지 않은 경우에는 손실함수 값이 최소한 '\\(W\\)의 행의 개수 - 1'이 되게 하여 계속 더 나은 \\(W\\)를 찾을 수 있게 한다.

#### 2) regularization

\- 만약 어떤 가중치 행렬 \\(W\\)가 손실함수 값을 0으로 만든다면, 그\\(W\\)에 상수배를 한 가중치 행렬 또한 손실함수 값을 0으로 만든다. 즉, 손실함수 값을 0으로 만드는 가중치 행렬의 개수는 무수히 많다. 그러나 그 모든 가중치 행렬이 실제 예측에 있어 모두 똑같은 정확도를 갖는 것은 아니다. 손실함수만을 통해 구한 가중치 행렬은 이를 구하는 과정에서 대입한 입력 데이터(훈련 데이터)에 대해서만 최적화돼있는 경우가 많고, 따라서 이렇게 구한 가중치 행렬이 훈련 데이터에서 사용하지 않은 전혀 다른 테스트 입력에 대해서도 정확한 결과를 내리라는 보장은 없다. 이 문제를 해결하기 위해 이제부터는 다음과 같은 모델을 생각한다.

$$
L(W) = {1 \over {N}} \sum_{i=1} ^{N} L_i(f(x_i, W), \, y_i) + \lambda R(W) \\
$$
(단, \\(x_i\\)는 훈련 데이터이고 \\(y_i\\)는 그것의 classification 열벡터이다.)

\- 여기서 \\(L(W)\\)는 가중치 행렬 \\(W\\)가 주어질 때 훈련 데이터셋 \\((x_1, y_1), \cdots, (x_n, y_n)\\)에 대한 손실을 계산하는 함수이고, 여기서 앞항은 그 \\(W\\)에 대한 각 훈련 데이터의 손실함수값을 계산해 이들의 평균을 구한 것이다. 그리고 여기서 뒷항은 이 '가능한 여러 개의 \\(W\\) 중 \\(L(W)\\)를 최소로 하는 \\(W\\)를 선택하는 문제'에서 **특정 사례에만 최적화(overfit)된 \\(W\\)를 제거**하기 위해 추가된 항이다. 이와 같은 의도로 \\(W\\)에 관한 항을 더하는 것을 정규화(regularization)라 하며, 정규화 항(\\(R(W)\\))을 어떻게 선택할 것인지와 그에 대해 얼만큼의 가중치(\\(\lambda\\)를 둘지가 문제가 된다.

\- 가장 흔히 쓰이는 정규화항은 \\(W\\)의 각 성분을 제곱한 후 모두 더한 것(\\(\sum_k \sum_l W_{k,l} ^2 \\))으로, L2 정규화라 한다. L2 정규화는 \\(W\\)의 어느 한 성분이 더 크고 나머지 성분이 아주 작은 \\(W\\)보다 **여러 성분이 고루 작은** \\(W\\)를 더 선호하는 경향이 있다.

\- 머신러닝에서는 일반적으로 모델이 고차원이 될수록 loss가 작은 \\(W\\)가 구해진다고 보지만, 한편으로 그렇게 구해진 \\(W\\)는 일반적인 데이터보다는 훈련 때 사용된 데이터에 훨씬 특화(overfit)되는 경향이 있다고 본다. 여기서 추가한 정규화 항은 이처럼 \\(W\\)의 overfit을 막기 위한 것이다. 정규화 항을 추가한 식의 값을 최소로 하는 \\(W\\)를 구할 경우 기존 loss만을 최소화하는 \\(W\\)보다는 약간 loss가 더 큰 경향이 나타나지만, 상대적으로 overfit에서는 자유로운 경향이 있다.


### 3. softmax loss(multinomial logistic regression)

\- \\(C\\)행의 가중치벡터 \\(W\\)와 이미지 데이터 열벡터 \\(x_i\\) (단, \\(i=1, \cdots, n\\))에 대하여 예측함수 \\(f(x_i, W)\\)의 각 행을 \\(s_k\\) (단, \\(k=1, \cdots, C)\\)이라 할 때, \\(x_i\\)가 \\(f\\)에 의해 \\(f\\)의 각 행에 해당하는 레이블로 분류될 확률 \\(P(Y=y_i \| X=x_i )\\)는 다음과 같이 쓸 수 있다.

$$
P(Y=k | X=x_i ) = { e^{s_k} \over \sum_j e^{s_j}}
$$

\- 이 \\(P(Y=k \| X=x_i )\\)를 softmax 함수라 하며, 이는 multiclass-SVM에서는 '점수'라는 의미만 있던 예측함수의 함수값의 각 성분에 '확률의 음수 로그'라는 의미를 부여한 것이다. (예측함수의 각 성분은 음수도 나올 수 있으나 음의 확률이라는 것은 존재하지 않기 때문에, 각 성분을 \\(e\\)의 지수로 취하여 양수값을 만들어낸 것이다.)

\- 한편 multiclass-SVM에서 보았듯 loss는 예측함수 함수값의 각 성분 사이 연산을 통해 구했으며, W가 적절하면 0이 되고 부적절하면 무한히 커졌다. 이러한 특성을 고려하여 **softmax loss function** \\(L_i\\)를 \\(-log P(Y=y_i \| X=x_i )\\)로 정의할 수 있다. 즉 softmax loss function을 '정확히 분류할 확률의 음수로그'라고 하면, 정확히 분류했을 땐 loss가 0이 되고 정확히 분류하지 못할 확률이 0에 가까워질수록 loss가 무한대에 가까워지는 식을 얻을 수 있다.

\- W의 값이 모두 0에 가깝게 작다면 \\(f(x_i, W)\\)의 각 성분은 모두 비슷한 값을 갖게 될 것이고, 그렇게 되면 softmax 함수의 값은 모두 \\(1 \over C\\)로 동일 할 것이다. 따라서 이때의 softmax loss function은 \\(log C\\)가 된다.

\- multiclass-SVM의 경우 hinge 형태의 그래프를 갖기 때문에 정답 레이블의 점수(\\(s_{y_i}\\))가 오답 레이블의 점수(\\(s_j\\))보다 1 이상 크기만 하다면(즉 \\(s_j - s_{y_i} + 1 \geq 0 \\) 이면) 정답 레이블 점수가 약간 달라지더라도 loss는 변하지 않았으나, softmax의 경우 **정답 레이블의 점수가 약간만 달라져도 loss는 반드시 변하게 돼있다.** 실제로는 이것이 multiclass-SVM과 아주 큰 차이를 나타내지는 않으나, 함수의 형태적 특성에 이러한 차이가 있다는 것을 알아둘 필요는 있다.



### 4. optimization

\- multiclass-SVM이든 softmax든 결국 loss 값을 최소로 하는 W를 찾는 게 핵심인데, 그 W를 어떤 방법으로 찾을 것인지가 문제가 된다. 

- 여러 번 무작위로 W를 만들고 매번 loss를 계산해 비교해보는 것이 떠올리기 가장 쉬운 방법이겠지만 당연히도 이 방법은 아주 어리석은 짓이다. 

- W의 각 성분을 아주 살짝 증가 또는 감소시켜 그때의 loss의 변화량을 계산하여 어떤 방향으로 W의 각 성분이 변해야 loss값이 더 작아질지를 판단하고 그 방향으로 W의 각 성분을 변화시켜보는 방법도 있다. 

  - 그러나 데이터셋은 보통 아주 방대하므로, 이렇게 W의 각 성분을 모두 조금씩 변화시키고 그때마다 loss를 계산하는 식으로는 굉장한 자원낭비가 있을 수밖에 없다.

  - 벡터의 gradient(벡터 각 성분의 partial derivative)를 구하여 훨씬 작은 자원을 사용하여 같은 결과를 얻을 수 있다. 실제 딥러닝에서는 이처럼 먼저 gradient를 구하며, 이를 구한 다음 수치계산을 통해 이를 검증한다. (이를 gradient check라 한다.)

\- W의 각 성분을 각각 어느 방향으로 변화시켜야 할지 알게 되었으면 이제 그 방향으로 W의 각 성분을 변화시켜나가면서 loss를 최소로 하는 W를 찾으면 된다. (이를 gradient descent라 한다.) 그러나, 얼만큼 W의 각 성분을 변화시켜야 하는지를 결정하는 것 또한 중요한 문제다. 이를 learning rate라 하며, 이 역시 딥러닝에서 모델을 학습시킬 때 결정해야 할 hyperparameter로서 가장 중요한 hyperparameter라 할 수 있다. (모든 hyperparameter 중 가장 먼저 결정해야 하는 hyperparameter다.)

- learning rate를 너무 작게 잡은 경우: loss가 충분히 감소하는 데까지 아주 오랜 시간이 걸린다.

- learning rate를 필요 이상 크게 잡은 경우: loss가 초기에는 빠르게 감소하나 학습이 어느 정도 진행된 뒤에는 좀처럼 줄지 않는 상황이 나타난다.

  - learning rate를 지나치게 크게 잡은 경우: loss가 줄지 않고 오히려 굉장히 크게 증가해버리는 상황이 나타난다.

\- learning rate를 크게 잡는 것은 위험하기 때문에 적절히 작은 learning rate를 선택해야 하는데, 그렇게 되면 훈련 데이터셋은 방대하므로 gradient descent에 굉장한 자원 소모가 있게 된다. 따라서 많은 경우 무작위적으로 선택한 100개 안팎의 적은 데이터셋(이를 mini batch라 한다)으로 현재 W의 loss를 빠른 시간 내에 추정하여 W를 업데이트하며 모델을 학습한다. (이를 stochastic gradient descent라 한다.)


### 5. representation learning

\- 실제 임의의 이미지에 대하여 어떠한 전처리도 거치지 않고 그대로 모델 학습 데이터셋으로 넣으면 과거에는 실제로는 학습이 잘 이루어지지 않았다. 그래서 과거에 흔히 사용했던 방법으로서, 한 이미지 안에 들어있는 여러 특징 표현을 각각 추출한 후 이들을 다시 하나로 이은 벡터를 만들고 그 벡터를 학습 데이터로 사용한 것이었다. 

- 이미지가 갖고 있는 특징 표현의 한 사례로 color histogram이 있다. 색상 스펙트럼이 있을 때 각 색깔마다 그에 해당하는 버킷을 각각 두고, 이미지의 각 픽셀의 색상만 보고 그 버킷에 담긴 픽셀수를 하나씩 증가시키는 것이다. 이렇게 얻은 histogram을 벡터로 만들어 학습 데이터로 사용할 수 있다.

- 오래 전부터 사용돼온 특징 표현의 하나로 HOG(histogram of oriented gradient)가 있다. 이미지를 적당히 작은 크기의 조각으로 잘게 쪼갠 후(예를 들면, 32 x 32 크기의 이미지를 8 x 8 크기의 조각 16개로 쪼개는 경우) 각 조각에서 지배적인 edge 방향이 어느 방향인지를 계산한 다음 '방향으로 만든 스펙트럼'의 각 방향에 해당하는 버킷이 있을 때 각 버킷에 담겨야 할 조각 개수를 세는 것이다.

- bag of words라는 특징 표현도 있는데, (1)먼저 대량의 이미지 데이터에서 각 이미지마다 무작위로 작은 이미지를 잘라내 이를 그와 유사한 이미지의 대표 이미지로 본다. (이렇게 만든 이미지 조각 모음을 코드북이라 한다.) (2)특징 표현을 얻어낼 이미지를 조각조각 분석해 코드북에 있는 이미지들이 그 이미지에 얼마나 자주 등장하는지 빈도 데이터를 얻는다.

\- 말하자면 전처리를 거치지 않은 데이터는 공간상에 불규칙하게 퍼져있는 점과 같은데, 상기한 것과 같이 특징 표현을 추출한 다음 다시 하나의 벡터로 이은 것과 같은 전처리는 데이터를 인간의 직관으로 공간상의 linear한 기준선을 경계로 구분한 것이다. (이를 좌표계 변환과 비슷하게 생각할 수도 있다.)

\- 그러나 딥러닝에서는 이처럼 이미지에서 특징을 인위적으로 추출하지 않고, 그냥 원본 데이터를 모델 학습에 그대로 대입하여 모델을 학습시킨다. 그러면 딥러닝의 신경망은 스스로 이미지로부터 특징을 추출하여 그에 대해 학습하게 된다.