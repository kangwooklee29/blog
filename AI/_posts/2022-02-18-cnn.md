---
title: CNN
---

### 1. 개요

\- deep MLP는 각 MLP 층 사이의 연결이 완전연결인데, 이 경우 학습이 매우 느리고 과적합이 발생할 수 있다. 각 MLP 층과 층 사이에 연결이 완전연결이 아니라 일부 노드끼리만 연결되는 neural network를 만들 수도 있으며 이러한 neural network를 CNN(convolutional neural network)라 한다. 

\- CNN의 경우 격자 구조를 갖는 데이터(데이터를 구성하는 성분들이 서로 인접했을 때 더 연관성이 높은 경우 등. 이미지 인식 등)를 다룰 때 적합하다.

\- CNN에서는 한 MLP에서 다음 MLP로 넘어갈 때 convolution 연산을 수행한다.


### 2. CNN에서 쓰이는 연산 및 개념

- convolution 연산: 주어진 입력 행렬을 커널 행렬과 연산하면, 입력 행렬의 지정된 영역과 커널 행렬의 각 성분을 서로 곱한 후 그 결과값을 다 더한 스칼라값을 얻는다. 이처럼 커널 행렬과의 연산을 통해 스칼라값 하나를 얻는 연산을 convolution 연산이라 한다.

- 커널 행렬: convolution 연산을 수행할 때 사용하는 행렬. 각 Conv층이 갖는 일종의 파라미터로서, 경사하강법을 통해 더 나은 값을 갖도록 값이 바뀌게 된다.

- stride: 예를 들어 입력 행렬의 가장 왼쪽 위부터 \\(n \times n\\) 크기의 영역과 \\(n \times n\\) 크기의 커널 행렬과 convolution 연산을 했고, 또 그 convolution 연산을 했던 입력 행렬의 위치에서 얼만큼 떨어진 위치에서부터 다시 \\(n \times n\\) 크기의 영역과 convolution 연산을 할 때, 처음 convolution 연산을 했던 위치와 그 다음으로 convolution 연산을 하는 위치 사이의 간격을 stride라 한다.

- padding: 입력 행렬의 모든 성분에 대해 convolution 연산을 하면 결과값으로서 입력 행렬의 크기와는 크기가 다른 행렬을 얻게 되는데, 이 결과 행렬의 크기를 필요에 따라 더 크게 얻고자 할 때 입력 행렬의 상하좌우에 0을 채워 입력 행렬의 크기를 키우는 경우가 있다. 이때 0을 채우는 연산을 padding이라 한다.

- pooling: 입력 행렬을 여러 블록으로 나눈 후, 각 블록에 있는 숫자들을 이용하여 각 블록에 숫자 하나를 할당하여 입력 행렬보다 크기가 작은 새로운 행렬을 구하는 연산을 pooling이라 한다. 각 블록에 있는 숫자들 중 최댓값을 각 블록의 대표값으로 하는 행렬을 구하는 것을 max pooling, 각 블록에 있는 숫자들의 평균을 각 블록의 대표값으로 하는 행렬을 구하는 것을 average pooling이라 한다.


### 3. CNN의 구조

1) 특징을 추출하는 층

- Conv층: convolution 연산을 수행한다.

- ReLU층: ReLU 연산을 수행한다.

- Pool층: Pool 연산을 수행한다. 연산의 양을 줄인다는 점에서 유용하나 최근에는 사용하지 않는 추세다.


2) 분류/회귀를 수행하는 MLP

- FC(fully connected)층: 각 MLP끼리 서로 완전히 연결돼 있다.

- 결과 예측 층: 분류를 수행하는 CNN이라면, 가장 마지막 층에서는 softmax 연산을 수행한다.

