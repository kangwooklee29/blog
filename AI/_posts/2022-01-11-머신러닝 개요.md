---
title: 머신러닝 - 머신러닝 개요
---

### 1. 개요

\- 컴퓨터가 **입력된 데이터를 통해 훈련을 해** 같은 **작업**을 전보다 **더 나은 성능**으로 할 수 있게 된다면 컴퓨터는 그 데이터로부터 '학습'을 했다고 이야기할 수 있다. 이와 같은 머신러닝의 개념은 1950년대에 처음 등장하여 점차 구체적으로 발전하기 시작했다.

- 머신러닝 중 지도학습(supervised learning)에서는 데이터를 입력할 때 '훈련시키고자 하는 데이터'와 '그 데이터에 대하여 정답으로 기대하는 결과'를 입력 데이터로 넣는다. 이때 머신러닝은 이들 입력 데이터로부터 학습을 해 보다 일반적인 데이터가 입력으로 주어지더라도 정답으로 기대되는 결과를 높은 정확도로 출력하는 **프로그램**을 **입력에 대한 결과**로서 내놓게 된다. 

- 이와 반대로 비지도학습(unsupervised learning)에서는 '입력 데이터에 대하여 정답으로 기대되는 결과'가 따로 없어 훈련 때 특별히 그런 결과가 훈련 데이터로 제공되지는 않는다. 이런 학습에서는 목표가 '기대되는 정답 내기'가 아니라 훈련 데이터들 각각이 지닌 공통의 특징들을 매개로 각각 서로 군집화(clustering)하는 것이 프로그램의 목적이 된다.

\- 처음에는 인간이 추출한 규칙(rule)을 기계가 학습하는 모델을 생각했으나, (1)우선 인간이 사물의 모든 규칙을 알고 있는 게 아니고 (2)학습 대상이 변화 양상이 극심한 경우에는 그 모든 규칙을 전부 다 나열하는 게 사실상 불가능하다. 따라서 나중에는 인간이 추출한 규칙이 아니라 아무 가공되지 않은 원본 데이터를 기계가 학습하고 그 원본 데이터가 갖고 있는 규칙은 기계가 스스로 찾아내게 하는 모델을 고안하게 되었다.

\- 머신러닝 문제는 크게 입력 데이터에 대한 특정한 실수값을 예측하는 문제(regression)와 입력 데이터를 수개의 선택지 중 어느 하나로 분류하는 문제(classification)로 나눌 수 있다.



### 2. 머신러닝이 적은 데이터로도 좋은 성능이 나오는 이유

\- 예를 들어 미 NIST에서 제공하는 MNIST라는 데이터베이스는 각 픽셀에 0 또는 1의 정보만 담겨있는 28x28 크기의 이미지 파일이 6만개 제공되며 각 이미지는 0부터 9까지의 숫자를 손으로 쓴 것 같은 이미지가 담겨있다. 각 픽셀에 0 또는 1의 정보만 담겨있는 28x28 크기의 이미지 파일의 가능한 총 경우의 수는 \\(2^{784}\\)로 6만이라는 숫자에 비하면 터무니없이 많은 수이다. 그러나 실제로 MNIST 데이터베이스로 머신러닝 훈련을 시켜보면, 불과 6만개에 불과한 훈련 데이터만으로도 6만개에 속하지 않는 일반적인 이미지 파일에 대해서도 굉장히 성공적으로 분류를 하는 모델을 얻을 수 있다. 이처럼 적은 수의 훈련 데이터만으로도 머신러닝 모델이 좋은 성능을 내는 이유로 다음과 같은 이유가 제시된다.

1) 실제 유의미한 특징을 갖고 있는 이미지는 \\(2^{784}\\)보다 훨씬 적다.

- 예를 들어 왼쪽 위 끝 픽셀만 1이고 나머지는 모두 0인 이미지 같은 이미지는 0부터 9까지 수 중 어느 것에도 해당하지 않으며, 이처럼 가능한 모든 경우의 수라는 \\(2^{784}\\)가지 이미지 중 0부터 9까지 수 중 어느 것에도 해당하지 않는 수가 훨씬 많다. 즉 머신러닝 모델이 0부터 9까지 수 중 어느 하나로 분류해야 할 대상이 되는 이미지의 수는 \\(2^{784}\\)보다 훨씬 적다.

2) manifold assumption

- 실제 손글씨 이미지는 28x28보다 훨씬 더 큰 공간에서 만들어지는 경우가 많기 때문에, 28x28 크기의 이미지라 하면 아주 저차원의 제한된 정보가 담겨있는 것처럼 생각할 수 있고(머신러닝에서는 입력 데이터를 벡터로 변환하기 때문에 입력 데이터의 크기=차원) 거기서도 훈련 이미지가 6만개에 불과하다 하면 극히 제한된 정보만 훈련 데이터로 사용하는 것처럼 생각하기 쉽다. 그러나 머신러닝에서 흔히 하는 가정으로, '고차원의 데이터가 갖고 있는 특징은 그 데이터를 저차원으로 투영해 보았을 때에도 여전히 나타난다'라는 가정이 있다. (이를 manifold assumption이라 한다.) 28x28 크기의 6만장의 이미지로도 좋은 성능이 나타나는 것은 이러한 관점에서 이해할 수 있다.