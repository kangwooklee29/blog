### 1. 마인드

\- 현업에서 얻게 되는 데이터 중에 '깨끗한 데이터'란 있을 수 없다. 실제 데이터를 수백 개씩 일일이 살펴보며 데이터가 제대로 돼있는지 확인할 필요가 있다. 

\- 회사의 규모가 커지면 회사의 DB에 담겨 있는 테이블 수도 어마어마하기 마련이고, 각 테이블이 각각 어떤 데이터를 담고 있는지 다 알고 있는 직원이 있을 수 없다. 이 문제를 해결하려면 각 테이블에 대한 documentation을 세심히 할 필요가 있으며, 또 이 문제 해결을 위한 다양한 툴(DataHub, Amundsen 등)을 사용하는 것 역시 한 방법이 될 수 있다.

### 2. 데이터 품질 체크 루틴

(1) 중복 레코드

```sql
SELECT COUNT(1) FROM table1;
SELECT COUNT(1) FROM (SELECT DISTINCT field1, field2 FROM table1); -- 재사용 필요가 없다면 그냥 이렇게 써도 되지만, 재사용을 고려하여 괄호 안 내용을 CTE로 새 테이블에 담아 쓰는 경우가 많다.
```

위 코드와 같이 DISTINCT 예약어 사용 전후 레코드 개수 차이를 세어 봄으로써 중복 레코드 여부를 알 수 있다.


(2) primary key uniqueness 

(3) 필요한 날짜의 레코드가 있는지 확인(예를 들어 최근 1달 이내 데이터가 필요한데, 최근 1달 이내 특정 시점부터 전산에 오류가 발생하여 그 이후 새로 갱신된 데이터가 없을 수 있다.)

(4) 결측치 제거
