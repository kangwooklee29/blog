---
title: CS231n - 컴퓨터비전, CNN의 역사
---


### 1. 역사

#### 1) 초기 역사


\- 1950년대 고양이를 통한 Hubel과 Wiesel의 포유류 시각 인지 연구. 사물의 테두리가 움직이면 그에 반응하는 단순한 세포들이 있는데 시각 인지에서는 이러한 단순한 세포들이 가장 중요. 시각 인지는 처음에는 이처럼 단순한 구조에서 시작하여 점점 복잡해져 나중에는 실제 세상을 인지. 

- 연구 내용을 조금 더 살펴보면, (1)같은 시각 인지 기능을 하는 신경세포들은 뇌의 피질의 한쪽 영역에 집중돼있음 (2)신경세포들은 계층적 구조를 가짐. 먼저 '단순세포'(단순히 빛 자극의 방향에 대해서만 반응하는 신경세포)가 있고, 이들 신경세포는 '복합세포'(빛의 방향과 움직임에 반응)와 연결돼 있었음. 그리고 이들은 '과복합세포'(선분의 끝지점 같은 시각 신호에 반응하는 신경세포)와 연결됨. (1980년 Kunihiko Fukushima가 이 개념을 활용하여 단순세포-복합세포 계층구조를 가진 신경망 모델을 제시함. 큰 성과는 없었지만..)

\- 60년대 초 컴퓨터 비전에 관한 최초의 박사논문인 Larry Roberts의 논문과 함께 컴퓨터 비전 연구의 역사가 처음 태동. Larry Roberts는 세상을 시각적으로 인지하고 이를 재구성하는 연구를 하여 사물을 기하학적 구조로 단순화. 이후 70년대부터는 '모든 사물은 단순한 기하학적 형태로 표현할 수 있다'라는 사고에 입각해 여러 연구가 진행. 그러나 이러한 시도는 너무 이상적이었고 toy example 수준에 불과. 

\- 1966년 MIT의 Seymour Papert의 the summer vision project가 유명. 참가자들을 이용하여 시각 시스템 구현.

\- 1970년대 출판된 MIT의 David Marr의 \<Vision\>이란 책도 유명. 컴퓨터 비전의 개념을 정의하고 발전 방향 및 시각인지 알고리즘이 어때야 하는지 구조를 제시. 이는 '비전이란 무엇인가'라는 질문에서 나아간 가장 직관적이고 이상적인 추론이고, 이러한 방식의 추론이 이후 수십년간 컴퓨터 비전 분야를 지배. 

- 실제 영상 단계

- primal sketch 단계: 실제 영상의 경계선, 선, 막대 등의 정보를 인지하는 단계. Hubel과 Wiesel의 논문에서 영감을 받은 것.

- 2.5D sketch 단계: primal sketch에서 깊이 정보 등을 인지하는 단계.

- 3D model 단계


#### 2) 90년대 이후


\- 컴퓨터 비전 분야의 발전이 답보상태이던 와중에, 90년대에 사물의 인식이 아니라 영상 분할(image segmentation, 이미지의 각 픽셀을 그룹화)을 먼저 수행하자는 의견이 등장. image segmentation에 관해 버클리의 Jitendra Malik, Jianbo Shi의 연구가 중요. 그래프 이론 도입.

\- 90년대 말부터 컴퓨터 비전 분야에서 '통계적 기계학습'이라는 방법이 주목.

\- 90년대 말부터 2010년경까지는 '특징 기반 사물 인식 알고리즘'이 대세. 특히 David Lowe의 SIFTfeature라는 알고리즘이 유명. 같은 물체라 해도 사진 찍은 위치에 따라 사진은 아주 달라 보일 수 있는데, Lowe는 물체의 시각적 특징 중 일부는 촬영 방식이 크게 달라지더라도 크게 변하지 않는 특성이 있음을 발견. Lower의 알고리즘은 물체에서 이러한 중요한 특징을 찾아내고 그 특징을 다른 사진에서 찾아내는 작업을 수행. Lowe의 알고리즘으로 컴퓨터 비전 분야는 크게 발전. 

\- 컴퓨터 비전 분야 중 얼굴인식 분야는 유독 발전속도가 빨랐는데, 특히 2001년 Paul Viola와 Michael Jones는 실시간 얼굴인식에 성공하기도. 이 덕분에 2006년 후지필름의 디카는 최초로 실시간 얼굴인식을 지원. 

\- 00년대 초, '컴퓨터 비전이 앞으로 풀어야 할 문제'가 무엇인지를 어느 정도 정의하게 됨. 이 시기에 당대의 사물 인식 기술이 어느 정도 수준에 이르렀는지 파악하는 연구 진행. 이러한 연구는 이후에도 계속 진행되었고 그때마다 사용된 유명한 데이터셋으로 PASCAL VOC(visual object challenge)가 있음. PASCAL VOC는 클래스당 수만 개의 이미지로 이루어진 20개의 클래스가 있음.

\- 00년대 중반 유명한 컴퓨터 비전에 관한 여러 ML 알고리즘들이 과적합 문제(학습 데이터에 대해서는 좋은 결과를 내지만 일반화 능력이 떨어져 새로운 데이터를 잘 판단하지 못하는 문제)를 겪고 있었고, 학습 데이터가 적을수록 과적합 문제는 더 심각했음. 이에 Fei-Fei Li는 PASCAL VOC보다 훨씬 큰 데이터셋인 ImageNet이라는 데이터셋의 구축(2만여 카테고리, 총 사진 약 1400만장)과 이를 활용한 알고리즘 성능 평가 대회(ILSVRC, ImageNet Large Scale Visual Acception Challenge)를 제안. 이후 컴퓨터 비전 기술은 급속도로 발달해 불과 몇 년만에 인간 수준에 이르기까지.

\- 2010년대 초반까지 컴퓨터 비전 알고리즘들은 고전적 개념을 유지. 2011년 ILSVRC에서 우승한 Lin의 알고리즘은 특징을 추출하는 단계, 특징을 계산하는 단계, pooling 단계 등을 거치며, 이는 여러 단계로 나뉘어 사물의 경계를 추출하고 불변 특징을 추출한다는 고전적 컴퓨터 비전 알고리즘들과 개념적으로 유사. (이러한 특징이 2012년 이후 알고리즘들에 전혀 없는 것은 아님.)

\- **2012년** ILSVRC에서 우승한 AlexNet은 그전에 출전한 다른 우승 알고리즘보다 훨씬 뛰어난 성능을 보였고, 이 알고리즘은 CNN(convolutional neural network)이라는 기술을 사용. (이 CNN이 소위 '딥 러닝'.) 이는 소위 '딥러닝 혁명'의 필수요소로 불리는 GPU를 통한 데이터 학습을 했기 때문에 가능한 것. 그리고 이게 CS231n에서 다룰 주 내용. (특히 image classification을 주로 다루고, 이의 응용문제도 다룸.)

\- 2012년부터 주목받게 된 딥러닝은 컴퓨터 비전은 물론이고 음성인식, 자연어처리 등의 분야 또한 획기적으로 발전시켜 그 우수성을 증명. 그만큼 컴퓨터 비전은 현재 AI 분야에서 가장 중요한 분야 중 하나. 

#### 3) CNN의 역사

\- 1957년 Frank Rosenblatt이 Mark I Perceptron이라는 기계를 발명. 이 기계는 카메라에 직접 연결되어 20x20 픽셀 크기의 이미지를 입력으로 받아 linear한 연산을 통해 얻은 함수값에 따라 0 또는 1을 출력하는, 최초의 linear classifier이자 최초의 perceptron 알고리즘 구현장치. 다만 이때는 backpropagation을 자동으로 한다는 개념이 없었기 때문에 가중치 벡터를 사람이 일일이 수정하면서 최적화를 해야 했음.

\- 1960년 Widrow와 Hoff가 Adaline, Madaline이라는 기계를 발명. 이들은 최초로 perceptron을 여러 layer로 연결한 neural network 장치. 그러나 이때까지도 backpropagation을 자동으로 한다는 개념은 없었고, 이 장치가 등장한 이후에도 큰 성과는 없어 neural network 관련 분야는 오래 정체상태에 머무름.

\- 1986년이 되어 비로소 Rumelhart 등이 처음으로 multi-layer perceptron의 개념을 구체화하고 backpropagation 등의 구체적 개념을 제시했으나, 이러한 개념이 등장한 뒤에도 neural network는 그다지 잘 동작하지 않음. 따라서 이 이후에도 오랫동안 neural network 분야는 정체상태에 머무름. 

- 이때 Rumelhart 등이 제시한 내용을 요약하면 다음과 같음.

(1) feature space를 변환하는 hidden layer를 둔다.

(2) 융통성 있는 의사 결정을 할 수 있도록, 활성함수로 sigmoid 함수를 사용한다.


\- 1998년 Jan LeCun이 backprogation 등의 개념을 활용하여 숫자 이미지를 인식하는 CNN 알고리즘을 제시. 숫자 이미지에 대해 탁월한 성능을 보였으나, 그보다 복합적인 이미지에 대해서는 좋지 않은 성능을 보인다는 단점이 있었음.

\- 2006년 Geoffrey Hinton, Ruslan Salakhutdinov가 backpropagation 등의 개념을 활용하여 Jan LeCun이 보인 것보다 훨씬 눈에 띄는 성과를 내는 데 성공하여 크게 화제가 됨. (deep learning이라는 이름이 이때 처음 붙음.) 이들이 제시한 모델은 다음 방식으로 동작.

(1) 전체 neural network를 두 layer 단위로 각각 나누어, 각 단위를 restricted Boltzmann machine이라는 방법으로 unsupervised machine learing을 수행한다.

- 나중에는 이 단계가 필요 없다는 사실이 알려짐. 이 당시 기술은 현재와 여러 모로 달랐는데, 대표적으로 neural network에서 activation function으로 sigmoid 함수를 이용했다는 점이 있음. sigmoid 함수는 현재는 거의 쓰이지 않음. 

(2) 모든 hidden layer의 가중치를 얻었으면 이를 이용하여 전체 neural network를 초기화한다.

(3) 초기화된 neural network에 대하여 backpropagation, fine tuning 등을 수행한다.

\- Geoffrey Hinton의 연구실에서 2010년 음성인식에 관해 굉장히 강력한 성과를 내는 딥러닝 모델을 최초로 발표했고, 2012년에는 AlexNet가 ILSVRC 우승하는 컴퓨터 비전 분야에서 획기적 사건을 일으키며 본격적으로 Geoffrey Hinton 등이 제시한 딥러닝 기술이 여러 사람들에게 적극적인 주목을 받기 시작. (이후 ILSVRC에서 우승한 알고리즘은 다 CNN. AlexNet의 CNN은 7계층짜리였지만 이후 우승한 알고리즘들은 더 깊은 계층을 사용. 2015년에 우승한 알고리즘은 152개의 계층을 사용.)

\- 왜 2012년? 

- 00년대를 거치며 하드웨어가 비약적으로 발전했다는 게 첫 번째. 성능이 나빠 주목이 떨어진 다른 옛날 알고리즘도 최신 하드웨어에서 구현하면 좋은 성능을 보이기도. 

- ImageNet 정도로 풍부한 양의 데이터가 00년대 이후 등장했다는 것도 중요한 이유. 

- 2010년 전후로 (1)가중치 행렬 초기화 성능이 좋아짐 (2)sigmoid보다 나은 activation function을 발견 같은 부분에서 딥러닝 기술이 크게 발전한 것도 있음. (sigmoid는 x가 너무 크거나 너무 작은 경우 기울기가 거의 변하지 않고, 따라서 경사하강법으로 파라미터를 갱신하는 경우 파라미터 갱신이 잘 되지 않을 때가 있다는 단점이 있음.)


\* 머신러닝 연구에서 현재 널리 쓰이는 데이터셋 중 CIFAR10이라는 데이터셋이 있음. 10개 클래스에 5만여 장의 이미지가 분포하고 있고 테스트용 이미지만 별도로 1만여 장을 제공. 각 이미지의 크기는 32 x 32이고, 3색 컬러로 이루어짐.


### 2. 강의 내용 및 목표

- image classification: 이미지를 입력으로 받아 이를 여러 개의 클래스 중 어느 하나로 분류하는 문제. 굉장히 제한적인 문제로 보이지만, 그 자체로 이미 충분히 유용하며 응용도 가능하다. 컴퓨터 비전 분야에서 핵심 문제로 꼽힌다.

- object detection: 분류된 클래스에 해당하는 물체가 실제 이미지 내 어디 위치한지를 정확히 알아내는 문제. image classification과는 다른 어려운 문제.

- image captioning: 이미지를 묘사하는 적절한 문장을 생성해내는 문제. image classification을 응용하여 해결할 수 있다.


\- 컴퓨터 비전 분야의 주요 목표는 '사람처럼 볼 수 있게 하기'. 그런 단계까지 나아가는 일은 아직은 힘든 일. 아직 풀지 못한 문제가 많다. 

- semantic segmentation, perceptual grouping 같은 문제는 이미지 전체를 레이블링하는 게 아니라 픽셀 하나하나의 의미를 해석하는 걸 목표로 한다. 

- 3D understanding: 실제 세계 재구성 문제.

- 행동 인식 문제

\- 인간은 이미지를 아주 잠깐만 보더라도 이를 묘사하는 장문의 글을 쓸 수 있다. 오래 볼 수 있다면 대하소설도 쓸 수 있을 것이다. 장난치는 사람들을 찍은 사진을 보고 사람들은 거기서 맥락을 읽어 웃으며 서로 사진을 공유하기도 한다. 현재의 컴퓨터 비전 기술은 이러한 맥락을 이해하는 것은 아직은 불가능하다. 컴퓨터 비전 분야의 목표는 이처럼 이미지의 내용을 아주 풍부하고 깊이 있게 이해하는 것이고, 아직은 풀어야 할 문제가 엄청나게 많다. 
