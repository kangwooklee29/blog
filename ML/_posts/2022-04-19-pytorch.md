#### * GPU 사용하기



```python
import torch
is_available = torch.cuda.is_available() #현재 CPU가 사용 가능한지 확인한다.
cuda = 'cuda' if is_available else 'cpu'
device = torch.device(cuda)
x = torch.randn(3, 4, device=cuda)
```

\- device('cuda') 메서드를 호출하면 이후 연산에서 사용할 프로세서를 GPU로 설정할 수 있다.

\- torch의 메서드를 호출하면서 파라미터로 device를 'cuda'로 지정하면 그 메서드를 수행하면서 사용할 프로세서로 GPU를 지정할 수 있다.

\- 컴퓨터에 여러 개의 GPU가 있는데 어떤 GPU가 이미 다른 프로그램에서 사용중이라 다른 GPU를 지정하고자 한다면, cuda 뒤에 :와 숫자를 지정하여 이미 사용중인 GPU와 다른 GPU를 선택 지정할 수 있다. 



#### * autograd

\- 텐서를 이용한 연산을 마치고 난 loss값이 저장된 텐서에 대해 backward() 메서드를 호출하면, 자동으로 그 loss값을 계산되게 한 중간 가중치 텐서의 gradient가 계산된다. (이처럼 PyTorch의 자동으로 gradient를 계산하는 엔진을 autograd 엔진이라 한다.) 단, 이런 식으로 역전파 연산을 하려면 그 가중치 텐서를 선언할 때 requires_grad 파라미터를 True로 전달해야 한다.

\- autograd 엔진은 메모리를 많이 쓰기 때문에, autograd 연산이 필요하지 않은 코드를 실행할 때에는 with torch_no_grad(): 구문으로 해당 코드 부분을 감싸 메모리를 절약한다.

\- autograd 연산을 한 이후 